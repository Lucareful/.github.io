<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Scrapy框架 on Luenci</title>
    <link>http://localhost:1313/tags/scrapy%E6%A1%86%E6%9E%B6/</link>
    <description>Recent content in Scrapy框架 on Luenci</description>
    <generator>Hugo -- 0.129.0</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/tags/scrapy%E6%A1%86%E6%9E%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>京东全网爬虫</title>
      <link>http://localhost:1313/articles/1/01/%E4%BA%AC%E4%B8%9C%E5%85%A8%E7%BD%91%E7%88%AC%E8%99%AB/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/1/01/%E4%BA%AC%E4%B8%9C%E5%85%A8%E7%BD%91%E7%88%AC%E8%99%AB/</guid>
      <description>完整代码见： https://github.com/Lucareful/JingDongSpider 写在前面： 折腾了很久的用python做爬虫项目到现在也该告一段落了，看视频学，遇到bug自己查找，代码思路不对重新写，环境不对自己配置&amp;hellip;.一路上跌跌撞撞，过程很艰苦，所幸结果为好。 代码就像一面明镜，照见我自身的不足。继续加油 需求 抓取首页的分类信息 大分类的url 中分类的url 小分类的url 抓取商品信息 商品名称 价格 评论信息 店铺 促销 选项 图片 开发环境和技术 技术选择： 由于全网爬虫</description>
    </item>
  </channel>
</rss>
